# Params
batch_size:  64
learning_rate_actor:  1e-3
learning_rate_actor_param:  1e-3
learning_rate_actor_min:  1e-5
learning_rate_actor_param_min:  1e-5
gamma:  0.8
layers:  [128]
indexed:  False
weighted:  False
average:  False
clip_grad:  10.
seed: 42
epsilon_final:  0.35
epsilon_steps:  60000
tau_actor_param: 0.001
epsilon_initial: 0.8
tau_actor: 0.01  # Polyak averaging factor for copying target weights
inverting_gradients: False
zero_index_gradients: False
norm_noise: False
random_weighted: False
priority: 0.1
use_ornstein_noise: False # if false, uses epsilon-greedy with uniform-random action-parameter exploration
evaluation_episodes: 1000
episodes: 7000
initial_memory_threshold:  3666
replay_memory_size:  80000
scale_actions:  True
initialise_params:  True
split:  False
multipass:  True
action_input_layer:  0
save_freq:  0
save_dir:  "results/platform"
render_freq:  100
save_frames:  False
visualise:  True
title:  "PDDQN"
balance_factor:  0.36
n_neighbour:  20
